---
title: 'Zero-Shot Robustification of Zero-Shot Models With Auxiliary Foundation Models'
date: 2023-07-19
permalink: /posts/2023/07/roboshot/
tags:
  - Multi-modal Models
  - Zero-shot inference
  - Robust ML
  - Language Models
excerpt: ''
authors: "<a href='https://dyahadila.github.io/'>Dyah Adila</a> and <a href='https://pages.cs.wisc.edu/~fredsala/'> Fred Sala </a>" 
---
Large pre-trained multi-modal models (e.g., OpenAI’s CLIP) are strong zero-shot predictors–achieving 77.9% zero-shot accuracy on CIFAR100. Now practitioners can use them out of the box for downstream prediction tasks without fine-tuning. Unfortunately, such models can adopt biases or unwanted correlations from their large-scale training data – making their predictions less reliable on samples that break in-distribution correlation. For instance, they might associate 'cow' with 'green'; because cow images are mostly depicted with pastures in the training data. But then, making wrong predictions on images of, let's say, cows on the beach.  Traditionally we can always fine-tune these models to get better performance on all groups in our test data. However, this breaks the promise of large pre-trained models – their capacity to be used out of the box. 

In this post we describe Roboshot: an approach to robustify pre-trained models and steering them away from these biases/correlations. What's more? RoboShot does this **without additional data and fine-tuning**! The core of our idea is inspired by embedding debiasing literature, which seeks to remove subspaces that contain predefined harmful or unwanted concepts. However, here we do not seek to produce fully-invariant embeddings; **our goal is simply to improve pre-trained model robustness** at low or zero cost.


# Zero-shot inference and modeling


Before diving in, let's first discuss and formulate the zero-shot inference setup. As has been studied in the literature, we can think of pre-trained models embedding space as spanning unknown concepts ${z_1, z_2, \ldots, z_k}$; then the embedding produced by pre-trained model $x$ is a mixture of concepts $\Sigma_i \gamma_i z_i$, where $\gamma_i \geq 0$ are weights.

Now, we describe the formulation for zero-shot binary classification (it is straightforward to extend to multi-class settings). We take $\Sigma_i \alpha_i z_i$ to be data sample embedding, and $c^0=\sum_i \beta_{i,0} z_i$ is the embedding of the first class, and $c^1=\sum_i \beta_{i,1} z_i$ is that of the second. Zero-shot prediction is made by 

<!-- ![zero-shot pred fig:zeroshot_pred](/images/blogposts/roboshot/zeroshot_pred.png|width=100px) -->
<img src="https://sprocketlab.github.io/images/blogposts/zeroshot_pred.png" style="height: 100px; width:100px;">

We predict the class that has the higher inner product with the datapoint's embedding.

We assume that input embedding mixture can be partitioned into three concept groups: harmful, helpful, and benign

$$  x = \sum_{s=1}^S \alpha_s^{\text{harmful}} z_s + \sum_{r=S+1}^{S+R} \alpha_r^{\text{helpful}} z_r + \sum_{b=S+R+1}^{S+R+B} \alpha_b^{\text{benign}} z_b. $$

For better illustration, we will start with a working example of a benchmark dataset: Watebirds. The task is to distinguish  $y \in {\texttt{waterbird}, \texttt{landbird}}$. The training data contains unwanted correlations between waterbird and water background, and landbird with land background. For the sake of illustration, let’s assume that in the embedding space, $z_{water} = -z_{land}$ and $z_{waterbird} = -z_{landbird}$.

Consider a test image of landbird over water, which does not follow the training correlations. In the embedding space, this might be  $x=0.7z_{\texttt{water}}+ 0.3 z_{\texttt{landbird}}$. We may also have class embeddings $c^{\texttt{waterbird}}=0.4z_{\texttt{water}}+0.6z_{\texttt{waterbird}} \text{ and }c^{\texttt{landbird}}=0.4z_{\texttt{land}}+0.6z_{\texttt{landbird}}.$. Then, the zero-shot prediction is $x^T c^{\texttt{waterbird}}= 0.1 > x^T c^{\texttt{landbird}}= -0.1$. This result in waterbird prediction, and thus is incorrect. We have seen how in this example, harmful components contained in $x$ caused wrong predictions. Now, we will demonstrate how Roboshot improves robustness against these unwanted correlations by reducing harmful components in embeddings and boosting the helpful ones.

# RoboShot

Suppose for our sample embedding $x$, we have a ground truth harmful component $v^{\texttt{harmful}}$ and ground truth beneficial component $v^{\texttt{helpful}}$. Note that in reality, we do not have access to the $v^{\texttt{harmful}}$ and $v^{\texttt{helpful}}$. We will describe the proxy for this ground truth component later. Roboshot reduces $v^{\texttt{harmful}}$’s effect on $x$ by classical vector rejection: 

![v_reject fig:v_reject](/images/blogposts/roboshot/v_reject.png)

Intuitively, this procedure subtracts $v^{\texttt{harmful}}$’s component on $x$. Similarly, to increase $v_{\texttt{helpful}}$’s influence, we can add $v^{\texttt{helpful}}$’s component along $x$, such that:

![u_accept fig:u_accept](/images/blogposts/roboshot/u_accept.png)

Let's try this on our example.

Suppose that $v^{\texttt{harmful}}=0.9z_{\texttt{water}}+0.1z_{\texttt{landbird}}$, and that this is our only harmful insight. Similarly, suppose that only have a single helpful insight given by $v^{\text{helpful}}=0.1z_{\texttt{water}}+0.9z_{\texttt{landbird}}$. First, to reduce $v^{harmful}$’s effect, we plug it into equation 2, resulting in $\hat{x} = -0.0244z_{\texttt{water}}+0.2195z_{\texttt{landbird}}.$
Making zero shot prediction with $\hat{x}$, we have that $x^T c^{\texttt{waterbird}}= -0.1415 < x^T c^{\texttt{landbird}}= 0.1415$. By removing a single component, we neutralize the harmful component and thus obtain the correct prediction. Now, let's see the effect of increasing $v^{helpful}$’s effect by plugging it into equation 3. This results in $\hat{x} = -0.0006z_{\texttt{water}}+0.4337z_{\texttt{landbird}}$, which further increase the classification margin. 

![algorithm fig:algorithm](/images/blogposts/roboshot/algorithm.png)
